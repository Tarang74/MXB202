%!TEX TS-program = xelatex
%!TEX options = -aux-directory=Debug -shell-escape -file-line-error -interaction=nonstopmode -halt-on-error -synctex=1 "%DOC%"
\documentclass{article}
\input{LaTeX-Submodule/template.tex}

% Additional packages & macros

% Header and footer
\newcommand{\unitName}{Advanced Calculus}
\newcommand{\unitTime}{Semester 2, 2023}
\newcommand{\unitCoordinator}{Dr Pascal Buenzli}
\newcommand{\documentAuthors}{Tarang Janawalkar}

\fancyhead[L]{\unitName}
\fancyhead[R]{\leftmark}
\fancyfoot[C]{\thepage}

% Copyright
\usepackage[
    type={CC},
    modifier={by-nc-sa},
    version={4.0},
    imagewidth={5em},
    hyphenation={raggedright}
]{doclicense}

\date{}

\begin{document}
%
\begin{titlepage}
    \vspace*{\fill}
    \begin{center}
        \LARGE{\textbf{\unitName}} \\[0.1in]
        \normalsize{\unitTime} \\[0.2in]
        \normalsize\textit{\unitCoordinator} \\[0.2in]
        \documentAuthors
    \end{center}
    \vspace*{\fill}
    \doclicenseThis
    \thispagestyle{empty}
\end{titlepage}
\newpage
%
\tableofcontents
\newpage
%
\section{Euclidean Space}
The Euclidean space \(\R^n\) is an \(n\)-dimensional vector space of real numbers.
This space is closed under addition and scalar multiplication.
\subsection{Operations}
\subsubsection{Addition}
The sum of two vectors \(\symbf{x}\) and \(\symbf{y}\) is defined element-wise
\begin{equation*}
    \symbf{x} + \symbf{y} = \begin{bmatrix}
        x_1 + y_1 \\
        x_2 + y_2 \\
        \vdots    \\
        x_n + y_n
    \end{bmatrix}
\end{equation*}
In a coordinate system, the vectors \(\symbf{x}\) and \(\symbf{y}\) are added tip-to-tail.
\subsubsection{Scalar Multiplication}
The scalar multiplication of a vector \(\symbf{x}\) by a scalar \(\lambda \in \R\) is defined element-wise
\begin{equation*}
    \lambda \symbf{x} = \begin{bmatrix}
        \lambda x_1 \\
        \lambda x_2 \\
        \vdots      \\
        \lambda x_n
    \end{bmatrix}
\end{equation*}
In a coordinate system, \(\lambda\) scales the vector \(\symbf{x}\) along the same line.
\subsubsection{Norm}
The norm (length) of a vector \(\symbf{x}\) is defined as
\begin{equation*}
    \norm{\symbf{x}} = \sqrt{\symbf{x} \cdot \symbf{x}} = \sqrt{\sum_{i=1}^n x_i^2}
\end{equation*}
The norm of a vector \(\symbf{x}\) is the distance from the origin to the tip of the vector.
This allows us to define the unit vector \(\hat{\symbf{x}}\) as
\begin{equation*}
    \hat{\symbf{x}} = \frac{\symbf{x}}{\norm{\symbf{x}}}
\end{equation*}
which is a vector of length 1 in the same direction as \(\symbf{x}\).
\subsubsection{Scalar Product}
The scalar product (dot product) of two vectors \(\symbf{x}\) and \(\symbf{y}\) is defined as
\begin{equation*}
    \symbf{x} \cdot \symbf{y} = \sum_{i=1}^n x_i y_i
\end{equation*}
The scalar product allows us to define the angle \(\theta\) between two vectors \(\symbf{x}\) and \(\symbf{y}\) as
\begin{equation*}
    \cos{\left( \theta \right)} = \hat{\symbf{x}} \cdot \hat{\symbf{y}}
\end{equation*}
where we use the unit vectors of \(\symbf{x}\) and \(\symbf{y}\), as the angle between two vectors is invariant under scaling.
Additionally, we can determine the projection of the vector \(\symbf{x}\) onto the vector \(\symbf{y}\) using trigonometry
\begin{equation*}
    \proj_{\symbf{y}} \left( \symbf{x} \right) = \left( \norm{\symbf{x}} \cos{\left( \theta \right)} \right) \hat{\symbf{y}} = \left( \norm{\symbf{x}} \left( \hat{\symbf{x}} \cdot \hat{\symbf{y}} \right) \right) \hat{\symbf{y}} = \left( \symbf{x} \cdot \hat{\symbf{y}} \right) \hat{\symbf{y}}
\end{equation*}
where \(\symbf{x} \cdot \hat{\symbf{y}}\) is the norm of the projection vector.
\subsection{Additional Properties}
\subsubsection{Triangle Inequality}
\begin{equation*}
    \norm{\symbf{x} + \symbf{y}} \leqslant \norm{\symbf{x}} + \norm{\symbf{y}}
\end{equation*}
\subsubsection{Inverse Triangle Inequality}
\begin{equation*}
    \norm{\symbf{x} - \symbf{y}} \geqslant \abs{\norm{\symbf{x}} - \norm{\symbf{y}}}
\end{equation*}
\subsubsection{Cauchy-Schwarz Inequality}
\begin{equation*}
    \abs{\symbf{x} \cdot \symbf{y}} \leqslant \norm{\symbf{x}} \norm{\symbf{y}}
\end{equation*}
\subsection{Multivariable Functions}
A multivariable function \(f\) maps a vector \(\symbf{x} \in \R^n\) to a real number \(f \left( \symbf{x} \right) \in \R\).
This function can be expressed in \textbf{explicit form} as
\begin{equation*}
    z = f\left( x,\: y \right)
\end{equation*}
or in \textbf{implicit form} as
\begin{equation*}
    F\left( x,\: y,\: z \right) = z - f\left( x,\: y \right)
\end{equation*}
These equations define a surface in \(\R^3\).
\subsubsection{Level Curves}
The level curves of a function \(f \left( x,\: y \right)\) are the curves in \(\R^2\) where
\begin{equation*}
    f \left( x,\: y \right) = c
\end{equation*}
where \(c\) is the height of the curve. Implicitly, this is equivalent to
\begin{equation*}
    F\left( x,\: y,\: z \right) = 0.
\end{equation*}
Level curves represent paths of equal height on the surface defined by \(z = f \left( x,\: y \right)\).
\subsection{Special Regions}
\subsubsection{Balls}
In an Euclidean space, an open ball of radius \(r > 0\) centred at a point \(\symbf{p} \in \R^n\)
is denoted \(B_r\left( \symbf{p} \right)\), and is defined as
\begin{equation*}
    B_r\left( \symbf{p} \right) = \left\{ \symbf{x} \in \R^n : \norm{\symbf{x} - \symbf{p}} < r \right\}.
\end{equation*}
This region includes all points less than a distance \(r\) from the vector \(\symbf{p}\),
where the distance is typically defined by the \(L_2\)-norm:
\begin{equation*}
    \norm{\symbf{x} - \symbf{p}}_2 = \left( \sum_{i=1}^n \left( x_i - p_i \right)^2 \right)^{1/2}.
\end{equation*}
\subsection{Mathematical Representation of Curves}
\subsubsection{Explicit Form}
A curve in \(\R^2\) can be represented in explicit form as
\begin{equation*}
    y = f\left( x \right)
\end{equation*}
but this is not possible in \(\R^3\) as a 3D curve requires two equations.
For a 2D explicit curve:
\begin{itemize}
    \item \(x\) is an independent variable such that we have 1 degree of freedom.
\end{itemize}
\subsubsection{Implicit Form}
A curve in \(\R^2\) can be represented in implicit form as
\begin{equation*}
    F\left( x,\: y \right) = 0.
\end{equation*}
In 3D, we must impose an additional equation that intersects a surface.
\begin{equation*}
    \left\{ \begin{aligned}
        F\left( x,\: y,\: z \right) & = 0 \\
        G\left( x,\: y,\: z \right) & = 0
    \end{aligned} \right.
\end{equation*}
In both cases, we have 1 degree of freedom as the degrees of freedom is the
difference between the number of variables and the number of equations.
\subsubsection{Parametric Form}
In parametric form, curves are parametrised in terms of a parameter \(t\).
In 2D, this is represented as
\begin{equation*}
    \symbf{r}\left( t \right) = \abracket*{x\left( t \right),\: y\left( t \right)}
\end{equation*}
and similarly in 3D,
\begin{equation*}
    \symbf{r}\left( t \right) = \abracket*{x\left( t \right),\: y\left( t \right),\: z\left( t \right)}
\end{equation*}
\subsection{Converting Between Representations}
\subsubsection{Explicit to Implicit}
The equation \(y = f\left( x \right)\) can always be converted to implicit form by rewriting it as
\begin{equation*}
    F\left( x,\: y \right) = y - f\left( x \right) = 0.
\end{equation*}
\subsubsection{Implicit to Explicit}
The equation \(F\left( x,\: y \right) = 0\) can be converted to explicit form if we can solve for \(y\) (or \(x\)):
\subsubsection{Parametric to Explicit/Implicit}
The equation \(\symbf{r}\left( t \right) = \abracket*{x\left( t \right),\: y\left( t \right)}\) can be written in
explicit or implicit form, if the parameter \(t\) can be eliminated from the simultaneous equations.
\subsubsection{Explicit to Parametric}
The equation \(y = f\left( x \right)\) can always be converted to parametric form by choosing the parameter \(t = x\), so that
\begin{equation*}
    \symbf{r}\left( t \right) = \abracket*{t,\: f\left( t \right)}.
\end{equation*}
\subsubsection{Implicit to Parametric}
The equation \(F\left( x,\: y \right) = 0\) can be converted to parametric form if we can find \(x = p\left( t \right)\) and \(y = q\left( t \right)\),
such that \(F\left( p\left( t \right),\: q\left( t \right) \right) = 0\), and
\begin{equation*}
    \symbf{r}\left( t \right) = \abracket*{p\left( t \right),\: q\left( t \right)}
\end{equation*}
for all \(t\).
\subsection{Paramaterisation}
To parametrise a curve, consider the following strategies:
\begin{itemize}
    \item For a closed curve, consider the polar parametrisation in terms of the angle \(\theta\):
          \begin{equation*}
              \symbf{r}\left( \theta \right) = \abracket*{R\left( \theta \right) \cos{\left( \theta \right)},\: R\left( \theta \right) \sin{\left( \theta \right)}}.
          \end{equation*}
    \item For a curve that is the intersection of two surfaces, consider one of the following mappings:
          \begin{equation*}
              x \mapsto \begin{bmatrix}
                  x                 \\
                  y\left( x \right) \\
                  z\left( x \right)
              \end{bmatrix} \qquad
              y \mapsto \begin{bmatrix}
                  x\left( y \right) \\
                  y                 \\
                  z\left( y \right)
              \end{bmatrix} \qquad
              z \mapsto \begin{bmatrix}
                  x\left( z \right) \\
                  y\left( z \right) \\
                  z
              \end{bmatrix}
          \end{equation*}
    \item Otherwise, consider a vector construction.
\end{itemize}
\subsubsection{Line Segments}
To parametrise a line segment from point \(A\) to \(B\), define the parameter \(t \in \interval{0}{1}\).
Then, consider the vectors \(\symbf{a} = \overline{OA}\) and \(\symbf{b} = \overline{OB}\).
By scaling the vector from \(A\) to \(B\) by \(t\), we can parametrise the line segment as
\begin{equation*}
    \symbf{r}\left( t \right) = \symbf{a} + t \left( \symbf{b} - \symbf{a} \right) = \symbf{a} \left( 1 - t \right) + \symbf{b} t.
\end{equation*}
\subsubsection{Circles}
To parametrise a circle of radius \(R\) centred at the \(\abracket*{x_0,\: y_0}\),
first parametrise the curve in terms of the angle \(\theta\), then shift the curve by \(\abracket*{x_0,\: y_0}\).
\begin{equation*}
    \symbf{r}\left( \theta \right) =
    \begin{bmatrix}
        x_0 \\
        y_0
    \end{bmatrix} +
    \begin{bmatrix}
        R \cos{\left( \theta \right)} \\
        R \sin{\left( \theta \right)}
    \end{bmatrix}
    =
    \begin{bmatrix}
        x_0 + R \cos{\left( \theta \right)} \\
        y_0 + R \sin{\left( \theta \right)}
    \end{bmatrix}
\end{equation*}
\subsubsection{Velocity Vectors}
The velocity vector of a parametrised curve \(\symbf{r}\left( t \right) = \begin{bmatrix}
    x\left( t \right) \\
    y\left( t \right)
\end{bmatrix}\) is defined as
\begin{equation*}
    \symbf{v}\left( t \right) = \symbf{r}'\left( t \right) = \lim_{\Delta t \to 0} \frac{\symbf{r}\left( t + \Delta t \right) - \symbf{r}\left( t \right)}{\Delta t} =
    \begin{bmatrix}
        x'\left( t \right) \\
        y'\left( t \right)
    \end{bmatrix}
\end{equation*}
where \(\symbf{v}\left( t \right)\) is a tangent vector to the curve at the point \(\symbf{r}\left( t \right)\), for all \(t\).
\subsubsection{Tangent Vectors}
Following from the definition of the velocity vector, the tangent vectors of a parametrised curve
are unit vectors in the direction of the velocity vector.
\begin{equation*}
    \hat{\symbf{\tau}}\left( t \right) = \pm \frac{\symbf{v}\left( t \right)}{\norm{\symbf{v}\left( t \right)}} = \pm \hat{\symbf{v}\left( t \right)}
\end{equation*}
For a curve given in explicit form \(y = f\left( x \right)\), the tangent vectors are given by
\begin{equation*}
    \hat{\symbf{\tau}}\left( x \right) = \pm \frac{1}{\sqrt{1 + \left( f'\left( x \right) \right)^2}} \begin{bmatrix}
        1 \\
        f'\left( x \right)
    \end{bmatrix}
\end{equation*}
\section{Multivariable Calculus}
\subsection{Multivariable Functions}
\begin{definition}[Multivariable Function]
    A multivariable function \(f\) maps several independent variables to a real number:
    \begin{equation*}
        f : E \subset \R^n \to \R
    \end{equation*}
    where
    \begin{align*}
        \abracket*{x_1,\: x_2,\: \ldots,\: x_n} & \mapsto z = f\left( x_1,\: x_2,\: \ldots,\: x_n \right) \\
        \symbf{x}                               & \mapsto z = f\left( \symbf{x} \right)
    \end{align*}
\end{definition}
\begin{definition}[Domain]
    The domain of \(f\) is the subset of \(\R^n\) for which \(f\) is defined.
    It corresponds to the set of all possible inputs to \(f\).
    \begin{equation*}
        \mathscr{D} \left( f \right) = E
    \end{equation*}
\end{definition}
\begin{definition}[Range]
    The range of \(f\) is the image of the domain \(E\) under \(f\):
    \begin{equation*}
        \mathscr{R} \left( f \right) = \left\{ f\left( \symbf{x} \right) \in \R : \symbf{x} \in E \right\}
    \end{equation*}
\end{definition}
\begin{definition}[Graph]
    The graph of \(f\) is the defined as the set
    \begin{equation*}
        G = \left\{ \abracket*{\symbf{x},\: f\left( \symbf{x} \right)} : \symbf{x} \in E \right\} \subset \R^{n + 1}
    \end{equation*}
\end{definition}
\subsection{Curves of Intersection}
\begin{definition}[Curves of Intersection]
    The curves of intersection of \(f\) with the plane \(x_i = c\) are defined as
    \begin{equation*}
        \left\{ \abracket*{x_1,\: x_2,\: \ldots,\: x_{i - 1},\: c,\: x_{i + 1},\: \ldots,\: x_n} : \abracket*{x_1,\: x_2,\: \ldots,\: x_n} \in E \right\}
    \end{equation*}
    In 3D, curves of intersection of \(z = f\left( x,\: y \right)\) with the planes perpendicular to the
    \(x\), \(y\), or \(z\)-axes allow us to represent the function in 3D.
    \begin{align*}
        \perp x \: (x = c)                             &  & \perp y \: (y = c)                             &  & \perp z \: (z = c)                                        \\
        z = f\left( c,\: y \right) = g\left( y \right) &  & z = f\left( x,\: c \right) = g\left( x \right) &  & c = f\left( x,\: y \right) \implies y = g\left( x \right)
    \end{align*}
\end{definition}
\begin{definition}[Level Set]
    The level sets of \(f\) are the set of all points in the domain of \(f\) that map to a given value \(c\).
    \begin{equation*}
        \left\{ \symbf{x} \in E : f\left( \symbf{x} \right) = c \right\}
    \end{equation*}
    In 2D, level sets are called \textbf{level curves}.
\end{definition}
\begin{definition}[Contour Map]
    The projection of all level curves onto the \(xy\)-plane is called the \textbf{contour map} of \(f\). T
    he lines of a contour map are called \textbf{contours}.
\end{definition}
\subsection{Derivatives}
\begin{definition}[Continuity]
    A function \(f\) is continuous at a point \(\symbf{x}_0\) if
    \begin{equation*}
        \forall \varepsilon > 0,\: \exists \delta > 0 : \norm{\symbf{x} - \symbf{x}_0} < \delta \implies \norm{f\left( \symbf{x} \right) - f\left( \symbf{x}_0 \right)} < \varepsilon
    \end{equation*}
    Equivalently, \(f\) is continuous at \(\symbf{x}_0\) when
    \begin{equation*}
        \lim_{n \to \infty} f\left( \symbf{x}_n \right) = f\left( \symbf{x}_0 \right)
    \end{equation*}
    for all sequences \(\left\{ \symbf{x}_n \right\} \) where \(\symbf{x}_n \to \symbf{x}_0\).

    A function \(f\) is continuous on a set \(E\) if it is continuous at every point in \(E\).
\end{definition}
\begin{definition}[Partial Derivatives]
    Partial derivatives represent the rate of change of a function with respect to one of its variables, holding all other variables constant.
    \begin{equation*}
        \pdv{f}{x_i} = f_{x_i} = \lim_{h \to 0} \frac{f\left( x_1,\: x_2,\: \ldots,\: x_i + h,\: \ldots,\: x_n \right) - f\left( x_1,\: x_2,\: \ldots,\: x_i,\: \ldots,\: x_n \right)}{h}
    \end{equation*}
\end{definition}
\begin{definition}[Higher-order Partial Derivatives]
    Higher-order partial derivatives are defined as
    \begin{equation*}
        \pdv[order=n]{f}{x_i} = \pdv{}{x_i} \left( \pdv[order={n - 1}]{f}{x_i} \right)
    \end{equation*}
\end{definition}
\begin{definition}[Mixed Partial Derivatives]
    Mixed partial derivatives are given the following notation
    \begin{equation*}
        \pdv{f}{x_i,x_j} = \pdv{}{x_i} \left( \pdv{f}{x_j} \right) = f_{x_i x_j}
    \end{equation*}
\end{definition}
\begin{theorem}[Schwarz's Theorem (or Clairaut's Theorem)]
    For a function \(f : E \subset \R^2 \to \R\) with \(\symbf{x}_a \in E\), if \(f_{xy}\) and \(f_{yx}\) are continuous on \(\symbf{x}_0\), then
    \begin{equation*}
        f_{xy} = f_{yx}
    \end{equation*}
\end{theorem}
\begin{remark}
    For an arbitrary \(n\) and \(k \leqslant n\), if all partials of order \(\leqslant \! k\) are continuous in the neighbourhood of \(\symbf{x}_0\),
    then mixed partials of order \(k\) are equal for any permutation of indices:
    \begin{equation*}
        \pdv[mixed-order=k]{f}{x_{i_1}...,x_{i_k}} = \pdv[mixed-order=k]{f}{x_{j_1}\ldots,x_{j_k}}
    \end{equation*}
\end{remark}
\subsection{Chain Rule}
For a function with multiple arguments, each argument of \(f\) that has an implicit dependence on the variable of differentiation
must be differentiated using the chain rule, where all contributions are summed.
\begin{gather*}
    \odv{}{t} f\left( x\left( t \right),\: y\left( t \right) \right) = \pdv{f}{x} \odv{x}{t} + \pdv{f}{y} \odv{y}{t} \\
    \pdv{}{u} f\left( x\left( u,\: v \right),\: y\left( u,\: v \right) \right) = \pdv{f}{x} \pdv{x}{u} + \pdv{f}{y} \pdv{y}{u}
\end{gather*}
\begin{definition}[Total derivative]
    The total derivative of a function \(f : \R^n \to \R\) is defined as
    \begin{equation*}
        \odv{f}{t} = \sum_{i = 1}^n \pdv{f}{x_i} \odv{x_i}{t} = \pdv{f}{x_1} \odv{x_1}{t} + \pdv{f}{x_2} \odv{x_2}{t} + \cdots + \pdv{f}{x_n} \odv{x_n}{t}
    \end{equation*}
\end{definition}
\begin{proof}
    Consider the case where \(n = 2\). The total derivative can be written as
    \begin{equation*}
        \odv{}{t} f\left( x\left( t \right),\: y\left( t \right) \right) = \lim_{\Delta{t} \to 0} \frac{1}{\Delta{t}} \left[ f\left( x\left( t + \Delta{t} \right),\: y\left( t + \Delta{t} \right) \right) - f\left( x\left( t \right),\: y\left( t \right) \right) \right]
    \end{equation*}
    Using the substitutions \(x\left( t + \Delta{t} \right) = x\left( t \right) + \Delta{x}\) and \(y\left( t + \Delta{t} \right) = y\left( t \right) + \Delta{y}\),
    \begin{align*}
        \odv{f}{t} & = \lim_{\Delta{t} \to 0} \frac{1}{\Delta{t}} \left[ f\left( x + \Delta{x},\: y + \Delta{y} \right) - f\left( x,\: y \right) \right]                                                                                                                                                   \\
                   & = \lim_{\Delta{t} \to 0} \frac{1}{\Delta{t}} \left[ f\left( x + \Delta{x},\: y + \Delta{y} \right) - f\left( x,\: y + \Delta{y} \right) + f\left( x,\: y + \Delta{y} \right) - f\left( x,\: y \right) \right]                                                                         \\
                   & = \lim_{\Delta{t} \to 0} \left[ \frac{\Delta{x}}{\Delta{t}} \frac{f\left( x + \Delta{x},\: y + \Delta{y} \right) - f\left( x,\: y + \Delta{y} \right)}{\Delta{x}} + \frac{\Delta{y}}{\Delta{t}} \frac{f\left( x,\: y + \Delta{y} \right) - f\left( x,\: y \right)}{\Delta{y}} \right] \\
                   & = \odv{x}{t} \pdv{f}{x} + \odv{y}{t} \pdv{f}{y}
    \end{align*}
\end{proof}
\begin{definition}[Gradient]
    The gradient is an operator that collects all partial derivatives of a function into a vector.
    \begin{equation*}
        \symbf{\nabla} = \begin{bmatrix}
            \partial_{x_1} \\
            \partial_{x_2} \\
            \vdots         \\
            \partial_{x_n}
        \end{bmatrix} \implies \symbf{\nabla} f = \begin{bmatrix}
            \partial_{x_1} f \\
            \partial_{x_2} f \\
            \vdots           \\
            \partial_{x_n} f
        \end{bmatrix}
    \end{equation*}
\end{definition}
The gradient allows us to define the chain rule using the dot product:
\begin{equation*}
    \odv{f}{t} = \symbf{\nabla} f \cdot \odv{\symbf{x}}{t}
\end{equation*}
\subsection{Directional Derivative}
The directional derivative of a function \(f : E \subset \R^n \to \R\) at a point \(\symbf{x}_0 \in E\) in the direction of a unit vector \(\hat{\symbf{u}} \in \R^n\)
is the slope of \(f\) in the direction of \(\symbf{u}\):
\begin{equation*}
    D_{\symbf{u}} f\left( \symbf{x}_0 \right) = \partial_{\symbf{u}} f\left( \symbf{x}_0 \right) = \lim_{h \to 0} \frac{f\left( \symbf{x}_0 + h \hat{\symbf{u}} \right) - f\left( \symbf{x}_0 \right)}{h}
\end{equation*}
\begin{proposition}
    The directional derivative can be computed using the gradient of \(f\)
    \begin{equation*}
        D_{\symbf{u}} f\left( \symbf{x}_0 \right) = \symbf{\nabla} f\left( \symbf{x}_0 \right) \cdot \hat{\symbf{u}}.
    \end{equation*}
\end{proposition}
\begin{proof}
    Consider the path in the output space \(g\left( s \right) = f\left( \symbf{x}_0 + s \hat{\symbf{u}} \right) \in \R\) for \(s \in \R\).
    The derivative of \(g\) w.r.t.\ \(s\) is given by:
    \begin{equation*}
        \odv{g}{s} = \lim_{h \to 0} \frac{g\left( s + h \right) - g\left( s \right)}{h}
    \end{equation*}
    where if we evaluate \(g\) at \(s = 0\), we get
    \begin{equation*}
        \odv{g}{s}_{s = 0} = \lim_{h \to 0} \frac{g\left( h \right) - g\left( 0 \right)}{h} = \lim_{h \to 0} \frac{f\left( \symbf{x}_0 + h \hat{\symbf{u}} \right) - f\left( \symbf{x}_0 \right)}{h} = D_{\symbf{u}} f\left( \symbf{x}_0 \right).
    \end{equation*}
    Using the derivative of the parametrised vector \(\symbf{x} = \symbf{x}_0 + s \hat{\symbf{u}} \in \R^n\):
    \begin{equation*}
        \odv{\symbf{x}}{s} = \hat{\symbf{u}}
    \end{equation*}
    we can evaluate the derivative of \(g\) w.r.t.\ \(s\) using the total derivative:
    \begin{align*}
        \odv{g}{s}_{s = 0} & = \sum_{i = 1}^n \pdv{f}{x_i}_{s = 0} \odv{x_i}{s}_{s = 0}         \\
                           & = \sum_{i = 1}^n \pdv{f}{x_i}_{s = 0} \hat{u}_i                    \\
                           & = \symbf{\nabla} f\left( \symbf{x} \right)_{s = 0} \cdot \hat{\symbf{u}} \\
                           & = \symbf{\nabla} f\left( \symbf{x}_0 \right) \cdot \hat{\symbf{u}}
    \end{align*}
    where \(\hat{u}_i\) is the \(i\)-th component of \(\hat{\symbf{u}}\).
    Therefore \(D_{\symbf{u}} f\left( \symbf{x}_0 \right) = \symbf{\nabla} f\left( \symbf{x}_0 \right) \cdot \hat{\symbf{u}}\).
\end{proof}
\begin{remark}
    Partial derivatives are directional derivatives in the direction of the canonical basis vectors \(\hat{\symbf{e}}_i\).
    \begin{equation*}
        \pdv{f}{x_i} = D_{\hat{\symbf{e}}_i} f
    \end{equation*}
    We can therefore say that the directional derivative is a generalisation of the partial derivative
    for any direction \(\hat{\symbf{u}}\).
\end{remark}
\begin{proposition}
    The gradient of a function \(\symbf{\nabla} f\) is orthogonal to the level curves of \(f\).
\end{proposition}
\begin{proof}
    Consider the path \(\symbf{x}\left( s \right)\) on a contour of \(f\). As \(f\) is constant on the contour,
    \begin{equation*}
        \pdv{f}{s} = 0.
    \end{equation*}
    Using the chain rule,
    \begin{equation*}
        \pdv{f}{s} = \sum_{i = 1}^n \pdv{f}{x_i} \pdv{x_i}{s} = \symbf{\nabla} f \cdot \odv{\symbf{x}}{s} = 0
    \end{equation*}
    therefore as the dot product is zero, \(\symbf{\nabla} f\) is orthogonal to the path \(\symbf{x}\left( s \right)\).
\end{proof}
\begin{proposition}
    The directional derivative is maximised when \(\hat{\symbf{u}}\) is parallel to \(\symbf{\nabla} f\).
\end{proposition}
\begin{proof}
    Using the angle definition of the dot product, the directional derivative is given by
    \begin{equation*}
        D_{\symbf{u}} f = \symbf{\nabla} f \cdot \hat{\symbf{u}} = \norm{\symbf{\nabla} f} \norm{\hat{\symbf{u}}} \cos{\theta} = \norm{\symbf{\nabla} f} \cos{\theta}
    \end{equation*}
    This expression is maximised when \(\cos{\theta} = 1\), or when \(\symbf{u}\) is parallel to \(\symbf{\nabla} f\).
\end{proof}
\begin{remark}
    The maximum slope of \(f\) at \(\symbf{x}_0\) is given by the magnitude of the gradient at \(\symbf{x}_0\):
    \begin{equation*}
        \max_{\hat{\symbf{u}}} D_{\symbf{u}} f\left( \symbf{x}_0 \right) = \norm{\symbf{\nabla} f\left( \symbf{x}_0 \right)}
    \end{equation*}
\end{remark}
\subsection{Normal Vectors to Curves}
\subsubsection{Parametric Curves}
For a parametric curve \(\symbf{r}\left( t \right)\), we find a normal vector \(\hat{\symbf{n}}\) such that
\begin{equation*}
    \hat{\symbf{n}} \cdot \symbf{r}'\left( t \right) = 0
\end{equation*}
where \(\symbf{r}'\left( t \right)\) is a tangent vector to the curve.
\subsubsection{Implicit Curves}
For an implicit curve \(F\left( x,\: y \right) = 0\), the normal vector is given by
\begin{equation*}
    \hat{\symbf{n}} = \pm \frac{\symbf{\nabla} F}{\norm{\symbf{\nabla} F}}
\end{equation*}
\subsubsection{Explicit Curves}
For an explicit curve \(y = f\left( x \right)\), we must convert the curve to implicit or parametric form.
\subsection{Normal Vectors to Surfaces}
\subsubsection{Parametric Surfaces}
\subsubsection{Implicit Surfaces}
For an implicit surface \(F\left( x,\: y,\: z \right) = 0\), the normal vector is given by
\begin{equation*}
    \hat{\symbf{n}} = \pm \frac{\symbf{\nabla} F}{\norm{\symbf{\nabla} F}}
\end{equation*}
\subsubsection{Explicit Surfaces}
For an explicit surface \(z = f\left( x,\: y \right)\), we can either convert the surface to implicit form,
or consider the tangents of two curves \(\symbf{r}_1\left( t \right)\) and \(\symbf{r}_2\left( t \right)\) on the surface.
Then we can find the normal vector by taking the cross product of the tangent vectors:
\begin{equation*}
    \hat{\symbf{n}} = \pm \frac{\symbf{r}_1'\left( t \right) \times \symbf{r}_2'\left( t \right)}{\norm{\symbf{r}_1'\left( t \right) \times \symbf{r}_2'\left( t \right)}}
\end{equation*}
\subsection{Tangent Vectors to Curves}
\subsubsection{Parametric Curves}
For a parametric curve \(\symbf{r}\left( t \right)\), the tangent vector is given by
\begin{equation*}
    \hat{\symbf{\tau}} = \pm \frac{\symbf{r}'\left( t \right)}{\norm{\symbf{r}'\left( t \right)}}
\end{equation*}
\subsubsection{Implicit Curves in 2D}
For an implicit curve \(F\left( x,\: y \right) = 0\), the tangent vector can be found by first
determining the normal vector \(\hat{\symbf{n}}\) which is proportional to the gradient of \(F\):
\begin{equation*}
    \hat{\symbf{n}} = \begin{bmatrix}
        n_1 \\
        n_2
    \end{bmatrix}
    \propto \symbf{\nabla} f
\end{equation*}
such that the tangent vector is given by
\begin{equation*}
    \hat{\symbf{\tau}} = \pm \begin{bmatrix}
        -n_2 \\
        n_1
    \end{bmatrix}
\end{equation*}
\subsubsection{Implicit Curves in 3D}
Given the intersectin of two implicit curves \(F\left( x,\: y,\: z \right) = 0\) and \(G\left( x,\: y,\: z \right) = 0\),
the tangent vector along the intersection is given by
\begin{equation*}
    \hat{\symbf{\tau}} = \pm \frac{\symbf{\nabla} F \times \symbf{\nabla} G}{\norm{\symbf{\nabla} F \times \symbf{\nabla} G}}
\end{equation*}
\subsubsection{Explicit Curves in 2D}
For an explicit curve \(y = f\left( x \right)\), we can either:
\begin{itemize}
    \item convert the curve to parametric form: \(\symbf{r}\left( t \right) = \abracket*{t,\: f\left( t \right)}\)
    \item convert the curve to implicit form: \(F\left( x,\: y \right) = y - f\left( x \right) = 0\)
\end{itemize}
\end{document}
